{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SUSS: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GRO: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BREW: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- IFMI: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- INTV: Data doesn't exist for startDate = 1414875600, endDate = 1463605200\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import yfinance as yf\n",
    "import string\n",
    "\n",
    "p = 14\n",
    "\n",
    "path = \"\"\n",
    "\n",
    "mmf = pd.read_excel(path + \"Market Manipulation Cases\\\\Market Manipulation Cases.xlsx\")\n",
    "\n",
    "mmf['Interval'] = mmf['End of MM'].sub(mmf['Start of MM'], axis=0)\n",
    "mmf['Interval'] = mmf['Interval'] + timedelta(days = 1)\n",
    "mmf['SideInterval'] = mmf['Interval'] * 2 + timedelta(days = 3)\n",
    "mmf['Start'] = mmf['Start of MM'] - mmf['SideInterval']\n",
    "mmf['Start'] = mmf['Start'] - timedelta(days = p)\n",
    "mmf['End'] = mmf['End of MM'] + mmf['SideInterval']\n",
    "\n",
    "for i in mmf.index:\n",
    "    if mmf.iloc[i, 3] == 1:\n",
    "        data = yf.download(mmf.iloc[i, 0], mmf.iloc[i, 7], mmf.iloc[i, 8])\n",
    "        data['Manipulated'] = [1 if x  >= mmf.iloc[i, 1] and x <= mmf.iloc[i, 2] else 0 for x in data.index]\n",
    "    \n",
    "        indeces_to_delete = data[ data['Volume'] == 0 ].index\n",
    "  \n",
    "        data.drop(indeces_to_delete, inplace = True)\n",
    "        string = path + \"Raw Separate Daily Data\\\\\" + mmf.iloc[i, 0] + \"_\" + str(int(mmf.iloc[i, 4])) + \".xlsx\"\n",
    "        data.to_excel(string, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#normalizaing and combining data\n",
    "\n",
    "import math\n",
    "np.seterr('raise')\n",
    "\n",
    "n = int(p - 2*(p/7))\n",
    "\n",
    "mmf = pd.read_excel(path + \"Market Manipulation Cases\\\\Market Manipulation Cases.xlsx\")\n",
    "\n",
    "alldays= pd.DataFrame(columns = ['Open','High', 'Low', 'Close', 'Adj Close', 'Volume', 'Manipulated', 'Company'])\n",
    "\n",
    "for ind in mmf.index:\n",
    "    if mmf.iloc[ind, 3] == 1:\n",
    "        i = mmf.iloc[ind, 0]\n",
    "        appear = str(int(mmf.iloc[ind, 4]))\n",
    "        comp = pd.read_excel(path + \"Raw Separate Daily Data\\\\\" + i + \"_\" + appear + \".xlsx\")\n",
    "        newcomp = pd.DataFrame(columns = ['Open','High', 'Low', 'Close', 'Adj Close', 'Volume', 'Manipulated'])\n",
    "        for j in comp.index:\n",
    "            if j > n - 1:\n",
    "                d = j - n\n",
    "                ap = (comp.iloc[d:j + 1, 0] + comp.iloc[d:j + 1, 3])/2\n",
    "                v = comp.iloc[d:j + 1, 5]\n",
    "                ap_by_v = ap*v\n",
    "                ap_by_v_sum = ap_by_v.sum(axis=0)\n",
    "                v = comp.iloc[d:j + 1, 5]\n",
    "                v_sum = v.sum(axis=0)\n",
    "                aap = ap_by_v_sum/v_sum\n",
    "                av = v_sum/ (n + 1)\n",
    "\n",
    "                ap_dif = ap - aap\n",
    "                ap_dif_s = ap_dif**2\n",
    "                ap_dif_s_by_v = ap_dif_s*v\n",
    "                ap_dif_s_by_v_sum = ap_dif_s_by_v.sum(axis=0)\n",
    "                aap_var = ap_dif_s_by_v_sum / v_sum\n",
    "\n",
    "                v_dif = v - av\n",
    "                v_dif_s = v_dif**2\n",
    "                v_dif_s_sum = v_dif_s.sum(axis=0)\n",
    "                v_var = v_dif_s_sum / (n)\n",
    "                \n",
    "                row = []\n",
    "                for l in range(0, 5):\n",
    "                    row.append((comp.iloc[j, l] - aap) / math.sqrt(aap_var))\n",
    "                row.append((comp.iloc[j, 5] - av) / math.sqrt(v_var))\n",
    "                row.append(int(comp.iloc[j, 6]))\n",
    "\n",
    "                newcomp.loc[len(newcomp)] = row\n",
    "\n",
    "        newcomp['Company'] = [i]*len(newcomp)\n",
    "        alldays = pd.concat([alldays, newcomp])\n",
    "    \n",
    "\n",
    "string = path + \"Normalized data\\\\\" + \"AllDays\" + \".xlsx\"\n",
    "alldays.to_excel(string, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting by the fact of manipulation\n",
    "\n",
    "manip_days = pd.DataFrame(columns = alldays.columns)\n",
    "not_manip_days = pd.DataFrame(columns = alldays.columns)\n",
    "\n",
    "for i in alldays.index:\n",
    "    if alldays.iloc[i, 6] == 1:\n",
    "        manip_days.loc[len(manip_days)] = alldays.iloc[i]\n",
    "    else:\n",
    "        not_manip_days.loc[len(not_manip_days)] = alldays.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomizing the days\n",
    "import random\n",
    "\n",
    "def randomize_rows(my_dataframe):\n",
    "    inds = my_dataframe.index\n",
    "    inds = list(inds)\n",
    "    rand_inds = random.sample(inds, len(inds))\n",
    "    rand_days = pd.DataFrame(columns = my_dataframe.columns)\n",
    "    for i in rand_inds:\n",
    "        rand_days.loc[len(rand_days)] = my_dataframe.loc[i]\n",
    "    return rand_days\n",
    "\n",
    "manip_days = randomize_rows(manip_days)\n",
    "not_manip_days = randomize_rows(not_manip_days)\n",
    "\n",
    "manip_days.to_excel(path + \"Normalized data\\\\\" + \"Manipulated Days\" + \".xlsx\", index = False)\n",
    "not_manip_days.to_excel(path + \"Normalized data\\\\\" + \"Not Manipulated Days\" + \".xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "manip_days = pd.read_excel(path + \"Normalized data\\\\\" + \"Manipulated Days\" + \".xlsx\")\n",
    "not_manip_days = pd.read_excel(path + \"Normalized data\\\\\" + \"Not Manipulated Days\" + \".xlsx\")\n",
    "\n",
    "x_m = manip_days.iloc[:, 0:6] \n",
    "y_m = manip_days.iloc[:, 6]\n",
    "\n",
    "x_n = not_manip_days.iloc[:, 0:6] \n",
    "y_n = not_manip_days.iloc[:, 6]\n",
    "\n",
    "l_m = int(len(x_m)*0.8)\n",
    "l_n = int(len(x_n)*0.8)\n",
    "\n",
    "x_train = pd.concat([x_m.iloc[:l_m, :], x_n.iloc[:l_n, :]])\n",
    "x_test = pd.concat([x_m.iloc[l_m:, :], x_n.iloc[l_n:, :]])\n",
    "y_train = pd.concat([y_m.iloc[:l_m], y_n.iloc[:l_n]])\n",
    "y_test = pd.concat([y_m.iloc[l_m:], y_n.iloc[l_n:]])\n",
    "\n",
    "y_test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN results:\n",
      "[[292  12]\n",
      " [  7  86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       304\n",
      "           1       0.88      0.92      0.90        93\n",
      "\n",
      "    accuracy                           0.95       397\n",
      "   macro avg       0.93      0.94      0.93       397\n",
      "weighted avg       0.95      0.95      0.95       397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, weights = 'distance')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#part that shows which companies are \"problematic\"\n",
    "# comps_m = manip_days.iloc[l_m:, 7]\n",
    "# comps_n = manip_days.iloc[l_n:, 7] \n",
    "# comps = pd.concat([comps_m, comps_n])\n",
    "# comps.reset_index(drop = True, inplace = True)\n",
    "# for i in y_test.index:\n",
    "#     #print(y_test.iloc[i])\n",
    "#     #print(y_pred[i])\n",
    "#     if y_test.iloc[i] == 1 and y_pred[i] == 0:\n",
    "#         print(comps.iloc[i])\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"KNN results:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB reulst:\n",
      "[[290  14]\n",
      " [ 85   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       304\n",
      "           1       0.36      0.09      0.14        93\n",
      "\n",
      "    accuracy                           0.75       397\n",
      "   macro avg       0.57      0.52      0.50       397\n",
      "weighted avg       0.68      0.75      0.69       397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(x_train, y_train)\n",
    "y_pred = gnb.predict(x_test)\n",
    "\n",
    "print(\"NB reulst:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT results:\n",
      "[[290  14]\n",
      " [  5  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       304\n",
      "           1       0.86      0.95      0.90        93\n",
      "\n",
      "    accuracy                           0.95       397\n",
      "   macro avg       0.92      0.95      0.94       397\n",
      "weighted avg       0.95      0.95      0.95       397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DT\n",
    "from sklearn import tree\n",
    "\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "tr = tr.fit(x_train, y_train)\n",
    "y_pred = tr.predict(x_test)\n",
    "\n",
    "print(\"DT results:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#tree.plot_tree(tr, max_depth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN results:\n",
      "[[295   9]\n",
      " [ 10  83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       304\n",
      "           1       0.90      0.89      0.90        93\n",
      "\n",
      "    accuracy                           0.95       397\n",
      "   macro avg       0.93      0.93      0.93       397\n",
      "weighted avg       0.95      0.95      0.95       397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240), max_iter=20000000)\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print(\"ANN results:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
